{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### download MNIST-M from https://github.com/mashaan14/MNIST-M/blob/main/MNIST-M.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_and_resize_images(data_dir, image_size=(32, 32)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Traverse directories\n",
    "    for digit in range(10):  # Digits 0 to 9\n",
    "        digit_dir = os.path.join(data_dir, str(digit))\n",
    "        image_files = os.listdir(digit_dir)\n",
    "        \n",
    "        # Load each image, resize and append it with its label\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(digit_dir, img_file)\n",
    "            image = Image.open(img_path).convert('RGB')  # Ensure it's in RGB\n",
    "            image = image.resize(image_size)\n",
    "            image = np.array(image, dtype=np.float64) / 255.0  # Convert to float64 and normalize\n",
    "            images.append(image)\n",
    "            labels.append(digit)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def create_balanced_subset(images, labels, subset_size_per_class):\n",
    "    subset_images = []\n",
    "    subset_labels = []\n",
    "    \n",
    "    for digit in range(10):  # Digits 0 to 9\n",
    "        idx = np.where(labels == digit)[0]\n",
    "        sampled_idx = random.sample(list(idx), subset_size_per_class)\n",
    "        subset_images.extend(images[sampled_idx])\n",
    "        subset_labels.extend(labels[sampled_idx])\n",
    "    \n",
    "    return np.array(subset_images), np.array(subset_labels)\n",
    "\n",
    "# Set paths to training and testing directories\n",
    "train_dir = 'path_to/MNIST-M/training'\n",
    "test_dir = 'path_to/MNIST-M/testing'\n",
    "\n",
    "# Load images from both training and testing directories\n",
    "train_images, train_labels = load_and_resize_images(train_dir)\n",
    "test_images, test_labels = load_and_resize_images(test_dir)\n",
    "\n",
    "# Create balanced subsets for training (15,000) and testing (5,000)\n",
    "train_subset_images, train_subset_labels = create_balanced_subset(train_images, train_labels, 1500)  # 1500 per class\n",
    "test_subset_images, test_subset_labels = create_balanced_subset(test_images, test_labels, 500)  # 500 per class\n",
    "\n",
    "# Optional: Shuffle the datasets if needed\n",
    "train_indices = np.arange(len(train_subset_images))\n",
    "test_indices = np.arange(len(test_subset_images))\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "train_subset_images = train_subset_images[train_indices]\n",
    "train_subset_labels = train_subset_labels[train_indices]\n",
    "test_subset_images = test_subset_images[test_indices]\n",
    "test_subset_labels = test_subset_labels[test_indices]\n",
    "\n",
    "print(f\"Training set:: {train_subset_images.shape}, {train_subset_labels.shape}, dtype: {train_subset_images.dtype}\")\n",
    "print(f\"Testing set:: {test_subset_images.shape}, {test_subset_labels.shape}, dtype: {test_subset_images.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_poisson_noise(images, noise_level=1.0):\n",
    "    \"\"\"\n",
    "    Adds Poisson noise to images.\n",
    "\n",
    "    Parameters:\n",
    "    - images: NumPy array of shape (N, H, W, C), where N is the number of images,\n",
    "              H is the height, W is the width, and C is the number of channels.\n",
    "    - noise_level: A float specifying the scaling factor for the noise. Higher values\n",
    "                  result in stronger noise.\n",
    "\n",
    "    Returns:\n",
    "    - noisy_images: NumPy array with Poisson noise added.\n",
    "    \"\"\"\n",
    "    # Ensure the images are properly scaled for adding noise\n",
    "    noisy_images = []\n",
    "    \n",
    "    # Loop over each image\n",
    "    for img in images:\n",
    "        # Ensure that image values are in the [0, 255] range (or [0, 1], depending on your input)\n",
    "        # This step assumes your images are in the range [0, 1]. If they are [0, 255], adjust accordingly.\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Scale the image by noise_level, add Poisson noise, then scale back\n",
    "        scaled_img = img * 255 * noise_level\n",
    "        noisy_img = np.random.poisson(scaled_img) / (255 * noise_level)\n",
    "        \n",
    "        # Clip to maintain valid image values\n",
    "        noisy_img = np.clip(noisy_img, 0, 1)\n",
    "        \n",
    "        noisy_images.append(noisy_img)\n",
    "    \n",
    "    return np.array(noisy_images)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def psf_blur_add_noise(image: np.ndarray, sigma: float = 1.0, noise_level: float = 0.01) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply PSF-like blurring to the image using a Gaussian filter and add noise.\n",
    "\n",
    "    Parameters:\n",
    "    - image: np.ndarray, the input image (assumed to be a 2D grayscale or 3D color array).\n",
    "    - sigma: float, the standard deviation for Gaussian kernel (blurring strength).\n",
    "    - noise_level: float, the standard deviation of Gaussian noise to be added.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray, the blurred and noisy image.\n",
    "    \"\"\"\n",
    "    if image.ndim == 3:  # Color image\n",
    "        blurred_image = np.zeros_like(image)\n",
    "        for i in range(image.shape[2]):  # Apply blur to each channel separately\n",
    "            blurred_image[..., i] = gaussian_filter(image[..., i], sigma=sigma)\n",
    "    else:  # Grayscale image\n",
    "        blurred_image = gaussian_filter(image, sigma=sigma)\n",
    "    \n",
    "    # Generate Gaussian noise\n",
    "    noise = np.random.normal(0, noise_level, image.shape)\n",
    "\n",
    "    # Add noise to the blurred image\n",
    "    noisy_blurred_image = blurred_image + noise\n",
    "\n",
    "    # Clip values to maintain valid pixel range [0, 1] for normalized image\n",
    "    noisy_blurred_image = np.clip(noisy_blurred_image, 0, 1)\n",
    "\n",
    "    return noisy_blurred_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy = add_poisson_noise(train_subset_images, 0.05)\n",
    "test_noisy = add_poisson_noise(test_subset_images, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PSF = [psf_blur_add_noise(train_subset_image, sigma=2.0, noise_level=0.00) for train_subset_image in train_subset_images]\n",
    "test_PSF = [psf_blur_add_noise(test_subset_image, sigma=2.0, noise_level=0.00) for test_subset_image in test_subset_images]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
